{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Contextual Compression Retriever\n",
        "\n",
        "Purpose: demonstrate `ContextualCompressionRetriever` which compresses retrieved documents with an LLM-based compressor before returning them. This reduces context size while keeping task-relevant information.\n",
        "\n",
        "Use when:\n",
        "- You need shorter, focused context for downstream generation,  \n",
        "- You want to remove irrelevant sections from long documents while preserving key facts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJf_drKTNhrF",
        "outputId": "02b91dad-0a0c-4b6d-953b-ee87c9ce17eb"
      },
      "outputs": [],
      "source": [
        "!pip install langchain chromadb openai tiktoken pypdf langchain_google_genai langchain-community wikipedia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites & install\n",
        "\n",
        "- Install packages (first cell).  \n",
        "- Provide the LLM API key (e.g., `GEMINI_API_KEY`) for compressor LLM.  \n",
        "- `faiss-cpu` recommended for local index building."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "7mg5xz2lNnrf"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "gemini_api_key = userdata.get('GEMINI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YchY5ps1XtCS",
        "outputId": "5008896b-59b6-4c44-ed88-c8cc9d5489a2"
      },
      "outputs": [],
      "source": [
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports & components\n",
        "\n",
        "This cell imports the FAISS adapter, embeddings, document types, `ContextualCompressionRetriever`, and an LLM-based extractor (`LLMChainExtractor`) used as a compressor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "0v6DGvGIRapH"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_core.documents import Document\n",
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1 — Prepare documents\n",
        "\n",
        "Provide documents with metadata. The compressor will remove or condense irrelevant parts when producing compressed results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "F5RLeCVrSP6u"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import Document\n",
        "\n",
        "# Step 1: Your source documents with metadata\n",
        "documents = [\n",
        "    Document(\n",
        "        page_content=\"Football is the most popular sport in the world, played by over 250 million players across more than 200 countries.\",\n",
        "        metadata={\"topic\": \"General\", \"source\": \"FIFA Stats\", \"year\": 2023}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Lionel Messi is known for his incredible dribbling, vision, and goal-scoring ability, earning multiple Ballon d'Or awards.\",\n",
        "        metadata={\"topic\": \"Player\", \"player\": \"Lionel Messi\", \"source\": \"Sports Illustrated\", \"year\": 2022}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"The FIFA World Cup is held every four years and is the most prestigious international football tournament.\",\n",
        "        metadata={\"topic\": \"Tournament\", \"name\": \"FIFA World Cup\", \"source\": \"FIFA\", \"year\": 2022}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Tactics in football involve formations, pressing strategies, and player roles that determine how a team controls the game.\",\n",
        "        metadata={\"topic\": \"Tactics\", \"source\": \"Coaching Manual\", \"year\": 2021}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Cristiano Ronaldo is a legendary footballer celebrated for his athleticism, goal-scoring, and leadership on the field.\",\n",
        "        metadata={\"topic\": \"Player\", \"player\": \"Cristiano Ronaldo\", \"source\": \"ESPN\", \"year\": 2022}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Football clubs like FC Barcelona, Real Madrid, and Manchester United have millions of fans worldwide.\",\n",
        "        metadata={\"topic\": \"Club\", \"source\": \"BBC Sport\", \"year\": 2023}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"The UEFA Champions League is an annual club competition that brings together the best European teams.\",\n",
        "        metadata={\"topic\": \"Tournament\", \"name\": \"UEFA Champions League\", \"source\": \"UEFA\", \"year\": 2023}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Youth development programs and football academies play a key role in nurturing the next generation of football stars.\",\n",
        "        metadata={\"topic\": \"Development\", \"source\": \"The Guardian\", \"year\": 2021}\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2 — Embeddings & vector index\n",
        "\n",
        "Create embeddings and a FAISS index. The index provides candidates to the base retriever which the compressor then shortens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "X2bQSic4Sk6K"
      },
      "outputs": [],
      "source": [
        "# Step 2: Initialize embedding model\n",
        "embeddings = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/gemini-embedding-001\",\n",
        "    google_api_key=gemini_api_key\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "9F1CUJJeSxQM"
      },
      "outputs": [],
      "source": [
        "# Step 3: Create Chroma vector store in memory\n",
        "vectorstore = FAISS.from_documents(\n",
        "    documents=documents,\n",
        "    embedding=embeddings\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Base retriever & compressor\n",
        "\n",
        "Create a base retriever (top-k) and an LLM-based compressor (LLMChainExtractor). The `ContextualCompressionRetriever` will call the compressor to shorten each candidate before returning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "YK_aFdhgpXcK"
      },
      "outputs": [],
      "source": [
        "base_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "tphvarRuk8lH"
      },
      "outputs": [],
      "source": [
        "model = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    google_api_key=gemini_api_key\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "2A5JMwAokq4O"
      },
      "outputs": [],
      "source": [
        "compressor = LLMChainExtractor.from_llm(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "wdAOo9XFpf4k"
      },
      "outputs": [],
      "source": [
        "# Create the contextual compression retriever\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_retriever=base_retriever,\n",
        "    base_compressor=compressor\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run query with compression\n",
        "\n",
        "Invoke the `compression_retriever.invoke(query)` to get compressed passages. These are ideal for passing as context to a generation model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "AAezPR8WTGu6"
      },
      "outputs": [],
      "source": [
        "query = \"Tell me about the most influential players and tournaments in football.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "cGpioJNDlh4Z"
      },
      "outputs": [],
      "source": [
        "compressed_results = compression_retriever.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z_Lh629TTxC",
        "outputId": "6db26594-f8fe-44c7-ab1a-12c1cec60510"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Result 1 ---\n",
            "The FIFA World Cup is held every four years and is the most prestigious international football tournament.\n",
            "\n",
            "--- Result 2 ---\n",
            "The UEFA Champions League is an annual club competition that brings together the best European teams.\n"
          ]
        }
      ],
      "source": [
        "for i, doc in enumerate(compressed_results):\n",
        "    print(f\"\\n--- Result {i+1} ---\")\n",
        "    print(doc.page_content)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
